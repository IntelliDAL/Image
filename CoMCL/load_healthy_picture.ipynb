{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试随机生成bbox，最后检查生成图片情况\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from config import DATA_CONFIG\n",
    "import random\n",
    "\n",
    "def data_transforms(patch):\n",
    "    data_aug = DATA_CONFIG['data_augmentation']\n",
    "    patch_size = DATA_CONFIG['patch_size']\n",
    "    mean,std = DATA_CONFIG['mean'],DATA_CONFIG['std']\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=data_aug['brightness'],\n",
    "                contrast=data_aug['contrast'],\n",
    "                saturation=data_aug['saturation'],\n",
    "                hue=data_aug['hue']\n",
    "            ),\n",
    "            transforms.RandomResizedCrop(\n",
    "                size=(patch_size, patch_size),\n",
    "                scale=data_aug['scale'],\n",
    "                ratio=data_aug['ratio']\n",
    "            ),\n",
    "            transforms.RandomAffine(\n",
    "                degrees=data_aug['degrees'],\n",
    "                translate=data_aug['translate']\n",
    "            ),\n",
    "            transforms.RandomGrayscale(0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ])\n",
    "    patch_1 = generate_patch(patch)\n",
    "    patch_2 = generate_patch(patch)\n",
    "    patch_1 = transform(patch_1)\n",
    "    patch_2 = transform(patch_2)\n",
    "    return patch_1,patch_2\n",
    "\n",
    "def generate_patch(img, bbox):\n",
    "    w, h = img.size\n",
    "    i = 0\n",
    "    # if i == 0 and len(bbox) == 4 :\n",
    "    #     print(\"bbox:\",bbox)\n",
    "    # if len(bbox) != 4:\n",
    "    #     print(\"bbox:\",bbox)\n",
    "    #     print(\"img_size:\",img.size)\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    # b_w = random.randint(32, 128)\n",
    "    # b_h = random.randint(32, 128)\n",
    "    # x1 = random.randint(10, w-b_w)\n",
    "    # y1 = random.randint(10, h-b_h)\n",
    "    # x2 = x1 + b_w\n",
    "    # y2 = y1 + b_h\n",
    "    b_w = bbox[2] - bbox[0]\n",
    "    b_h = bbox[3] - bbox[1]\n",
    "\n",
    "    x_space = 128 - b_w\n",
    "    if x1 < w - b_w:\n",
    "        l_shift = int(random.random() * min(x1, x_space))\n",
    "        new_x1 = x1 - l_shift\n",
    "        new_x2 = x2 + (x_space - l_shift)\n",
    "    else:\n",
    "        r_shift = int(random.random() * min(w - b_w, x_space))\n",
    "        new_x1 = x1 - (x_space - r_shift)\n",
    "        new_x2 = x2 + r_shift\n",
    "\n",
    "    y_space = 128 - b_h\n",
    "    if y1 < h - b_h:\n",
    "        t_shift = int(random.random() * min(y1, y_space))\n",
    "        new_y1 = y1 - t_shift\n",
    "        new_y2 = y2 + (y_space - t_shift)\n",
    "    else:\n",
    "        d_shift = int(random.random() * min(h - b_h, y_space))\n",
    "        new_y1 = y1 - (y_space - d_shift)\n",
    "        new_y2 = y2 + d_shift\n",
    "\n",
    "    patch = img.crop((new_x1, new_y1, new_x2, new_y2))\n",
    "    return patch\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "path = '/dataset/evaluate/train/0/10_left.jpeg'\n",
    "image = pil_loader(path)\n",
    "for i in range(10):\n",
    "    x1 = random.randint(60,452)\n",
    "    x2 = random.randint(60,452)\n",
    "    y1 = random.randint(60,452)\n",
    "    y2 = random.randint(60,452)\n",
    "    bbox = [x1,x2,y1,y2]\n",
    "    img = generate_patch(image,bbox)\n",
    "    patch_1,patch_2 = data_transforms(img)\n",
    "    save_path = '/dataset/lesion_image/healthy/'+str(i)+path.split('/')[-1]\n",
    "    patch_1.save(save_path,quality=95,subsampling=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7281\n",
      "2184\n",
      "训练集全部图片： {'0': 25810, '1': 2443, '2': 5292, '3': 873, '4': 708}\n",
      "训练集所使用的图片 {'0': 0, '1': 1411, '2': 4356, '3': 834, '4': 680}\n",
      "验证集全部图片: {'0': 8130, '1': 720, '2': 1579, '3': 237, '4': 240}\n",
      "验证集所使用的图片 {'0': 0, '1': 433, '2': 1292, '3': 228, '4': 231}\n",
      "训练集所使用的patch分布 {'0': 0, '1': 3132, '2': 16757, '3': 7004, '4': 4627}\n",
      "验证集所使用的patch分布 {'0': 0, '1': 937, '2': 4842, '3': 1779, '4': 1552}\n"
     ]
    }
   ],
   "source": [
    "#遍历pkl文件，给出lesion数量和lesion所属label\n",
    "import pickle,re\n",
    "import os\n",
    "\n",
    "# data = pickle.load(open('/dataset/lesion_predictions_new/EyePACS_newpredictions_128_08.pkl','rb'))\n",
    "data = pickle.load(open('./lesion_predictions/EyePACS_lesion_128.pkl','rb'))\n",
    "dict1 = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "dict2 = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "lesion_train = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "lesion_val = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "\n",
    "for train_val in data:\n",
    "    print(len(data[train_val]))\n",
    "    for img_path,lesion in data[train_val].items():\n",
    "        label = re.split('/|\\\\\\\\',img_path)[-2]\n",
    "        if train_val == 'train':\n",
    "            dict1[label] += 1\n",
    "            lesion_train[label] += len(lesion)\n",
    "        elif train_val == 'val':\n",
    "            dict2[label] += 1\n",
    "            lesion_val[label] += len(lesion)\n",
    "\n",
    "datapath = '/dataset/evaluate'\n",
    "train_class_num = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "val_class_num = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "for i in os.listdir(datapath):\n",
    "    for j in os.listdir(os.path.join(datapath,i)):\n",
    "        \n",
    "        path = os.path.join(datapath,i)+'/'+j\n",
    "        files = os.listdir(path)\n",
    "        if i == 'train':\n",
    "            train_class_num[j] = len(files)\n",
    "        elif i == 'val':\n",
    "            val_class_num[j] = len(files)\n",
    "\n",
    "print('训练集全部图片：',train_class_num)\n",
    "print('训练集所使用的图片',dict1)\n",
    "print('验证集全部图片:',val_class_num)\n",
    "print('验证集所使用的图片',dict2)\n",
    "\n",
    "print('训练集所使用的patch分布',lesion_train)\n",
    "print('验证集所使用的patch分布',lesion_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(247.48550347222223, 257.4816160159716, 275.11972656250003, 304.0486912156167), (275.38743489583334, 211.3676519520852, 295.60091145833337, 238.13007431233365), (386.54500868055555, 298.80018855368235, 399.4493923611111, 323.59571872227156)]\n",
      "[(297, 196, 181, 82), (377, 138, 173, 197), (202, 393, 274, 236), (196, 140, 446, 155), (219, 159, 113, 291), (202, 445, 403, 440), (248, 348, 154, 246), (432, 142, 297, 429), (187, 119, 232, 252), (222, 91, 183, 152)]\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open('./lesion_predictions/EyePACS_lesion_128.pkl','rb'))\n",
    "\n",
    "flag = 0\n",
    "for train_val in data:\n",
    "    for img_path,lesion in data[train_val].items():\n",
    "        if flag == 0:\n",
    "            flag += 1\n",
    "            print(lesion)\n",
    "        break\n",
    "    \n",
    "import random\n",
    "bbox = []\n",
    "for i in range(10):\n",
    "    x1 = random.randint(60,452)\n",
    "    x2 = random.randint(60,452)\n",
    "    y1 = random.randint(60,452)\n",
    "    y2 = random.randint(60,452)\n",
    "    bbox.append((x1,x2,y1,y2))\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21578\n",
      "6736\n",
      "14297 4552\n"
     ]
    }
   ],
   "source": [
    "#生成数据集\n",
    "import pickle,re\n",
    "import os\n",
    "import random\n",
    "data = pickle.load(open('/dataset/lesion_predictions_new/EyePACS_newpredictions_128_08.pkl','rb'))\n",
    "\n",
    "dict1 = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "dict2 = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "lesion_train = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "lesion_val = {'0':0,'1':0,'2':0,'3':0,'4':0}\n",
    "\n",
    "lesion_dataset = {}\n",
    "healthy_dataset = {}\n",
    "healthy_picture_train = [] #记录误诊为健康图片的数组，加入到healthy_dataset中\n",
    "healthy_picture_val = []\n",
    "#分离lesion和healthy\n",
    "for train_val in data:\n",
    "    if train_val not in lesion_dataset.keys():\n",
    "        lesion_dataset[train_val] = {}\n",
    "    if train_val not in healthy_dataset.keys():\n",
    "        healthy_dataset[train_val] = {}\n",
    "    print(len(data[train_val]))\n",
    "    for img_path,lesion in data[train_val].items():\n",
    "        label = re.split('/|\\\\\\\\',img_path)[-2]\n",
    "        img_picture = re.split('/|\\\\\\\\',img_path)[-1]\n",
    "        if train_val == 'train':\n",
    "            dict1[label] += 1\n",
    "            lesion_train[label] += len(lesion)\n",
    "            if label != '0':\n",
    "                lesion_dataset[train_val][img_path] = lesion\n",
    "            else:\n",
    "                healthy_dataset[train_val][img_path] = lesion\n",
    "                healthy_picture_train.append(img_picture)\n",
    "        elif train_val == 'val':\n",
    "            dict2[label] += 1\n",
    "            lesion_val[label] += len(lesion)\n",
    "            if label != '0':\n",
    "                lesion_dataset[train_val][img_path] = lesion\n",
    "            else:\n",
    "                healthy_dataset[train_val][img_path] = lesion\n",
    "                healthy_picture_val.append(img_picture)\n",
    "\n",
    "datapath = '/dataset/evaluate' #从数据集健康的图中提取健康的patch\n",
    "for train_val in os.listdir(datapath):\n",
    "    for label in os.listdir(os.path.join(datapath,train_val)):\n",
    "        path = os.path.join(datapath,train_val)+'/'+label\n",
    "        for  img_files in os.listdir(path):\n",
    "            if label == '0':\n",
    "                if train_val == 'train':\n",
    "                    if img_files not in healthy_picture_train:\n",
    "                        #随机选取bbox,加入健康patch\n",
    "                        bbox = []\n",
    "                        for i in range(4):\n",
    "                            x1 = random.randint(60,452)\n",
    "                            x2 = random.randint(60,452)\n",
    "                            y1 = random.randint(60,452)\n",
    "                            y2 = random.randint(60,452)\n",
    "                            bbox.append((x1,x2,y1,y2))\n",
    "                        img_path = datapath + '/' + train_val + '/' + label + '/' + img_files\n",
    "                        healthy_dataset[train_val][img_path] = bbox\n",
    "                elif train_val == 'val':\n",
    "                    if img_files not in healthy_picture_val:\n",
    "                        #随机选取bbox,加入健康patch\n",
    "                        bbox = []\n",
    "                        for i in range(4):\n",
    "                            x1 = random.randint(60,452)\n",
    "                            x2 = random.randint(60,452)\n",
    "                            y1 = random.randint(60,452)\n",
    "                            y2 = random.randint(60,452)\n",
    "                            bbox.append((x1,x2,y1,y2))\n",
    "                        img_path = datapath + '/' + train_val + '/' + label + '/' + img_files\n",
    "                        healthy_dataset[train_val][img_path] = bbox\n",
    "\n",
    "print(len(healthy_picture_train),len(healthy_picture_val))\n",
    "with open('./lesion_predictions/EyePACS_healthy_128.pkl', 'wb') as f:\n",
    "    pickle.dump(healthy_dataset, f)\n",
    "with open('./lesion_predictions/EyePACS_lesion_128.pkl', 'wb') as f2:\n",
    "    pickle.dump(lesion_dataset,f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from data import generate_dataset_from_pickle,data_transforms\n",
    "from config import DATA_CONFIG\n",
    "\n",
    "data_config = DATA_CONFIG\n",
    "data_index = './lesion_predictions/EyePACS_128.pkl'\n",
    "\n",
    "data_path = '/dataset/evaluate/'\n",
    "data_transform = data_transforms(data_config)\n",
    "train_dataset,val_dataset = generate_dataset_from_pickle(data_path,data_index,data_config,data_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=20,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "progress = tqdm(enumerate(train_loader))\n",
    "#1290,364 iteration\n",
    "\n",
    "for step,lesion in progress:\n",
    "    X1,X2,H = lesion\n",
    "    if step  == 0 :\n",
    "        print(len(X1))\n",
    "        for i in H:\n",
    "            print(len(i))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,re\n",
    "import os\n",
    "\n",
    "# data = pickle.load(open('/dataset/lesion_predictions_new/EyePACS_newpredictions_128_08.pkl','rb'))\n",
    "data = pickle.load(open('./lesion_predictions/EyePACS_128.pkl','rb'))\n",
    "normal_data = pickle.load(open('/dataset/lesion_predictions_new/EyePACS_newpredictions_128_08.pkl','rb'))\n",
    "val = normal_data['val']\n",
    "train = {}\n",
    "for i,j in data.items():\n",
    "    for train_val,lesion in data[i].items():\n",
    "        if train_val == 'train':\n",
    "            train[i] = lesion\n",
    "\n",
    "new_data = {'train':train,'val':val}\n",
    "with open('./lesion_predictions/EyePACS_128.pkl', 'wb') as f:\n",
    "    pickle.dump(new_data, f)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67f1dc6f6f712f7142079021955b91e049abb319dcfdc9eed010dd73dd4d845d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
